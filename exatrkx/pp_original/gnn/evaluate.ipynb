{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5ee84b9-169a-4e3f-8629-390e40e281da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import knn\n",
    "\n",
    "from sphenix_benchmark.utils import Cumulator, Checkpointer\n",
    "from sphenix_benchmark.datasets.tpc_dataset_with_edge import TPCDataset\n",
    "from sphenix_benchmark.models.mlp import MLP\n",
    "from sphenix_benchmark.metrics import compute_roc, compute_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f914429-1ace-47f5-bafd-68448cbc2d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TPCDataset in module sphenix_benchmark.datasets.tpc_dataset_with_edge:\n",
      "\n",
      "class TPCDataset(torch.utils.data.dataset.Dataset)\n",
      " |  TPCDataset(mmap_root, split, target=None, gnn=False, load_edge=False, **kwargs)\n",
      " |\n",
      " |  Load mmap_ninja data with optional filtering on multiplicity\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      TPCDataset\n",
      " |      torch.utils.data.dataset.Dataset\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __getitem__(self, index)\n",
      " |\n",
      " |  __init__(self, mmap_root, split, target=None, gnn=False, load_edge=False, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  __len__(self)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __annotations__ = {}\n",
      " |\n",
      " |  __parameters__ = ()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      " |\n",
      " |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      " |\n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |\n",
      " |  __class_getitem__(...) from builtins.type\n",
      " |      Parameterizes a generic class.\n",
      " |\n",
      " |      At least, parameterizing a generic class is the *main* thing this\n",
      " |      method does. For example, for some generic class `Foo`, this is called\n",
      " |      when we do `Foo[int]` - there, with `cls=Foo` and `params=int`.\n",
      " |\n",
      " |      However, note that this method is also called when defining generic\n",
      " |      classes in the first place with `class Foo[T]: ...`.\n",
      " |\n",
      " |  __init_subclass__(...) from builtins.type\n",
      " |      Function to initialize subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TPCDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f579276b-09fd-4cdb-8f93-120a0d7616fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from processor import Processor\n",
    "from models import assemble_gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edeb72db-618a-4081-850e-568ad3040896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse.csgraph as scigraph\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc8718eb-23b8-4dec-a685-7add8f4f9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/yhuang2/PROJs/FM_Exploration_benchmark_local/eval/')\n",
    "from efficiency_purity import calc_efficiency_purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a89c9702-0bcf-4098-aa43-b1980f47ade8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 12 13:30:41 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A6000               Off |   00000000:01:00.0 Off |                  Off |\n",
      "| 30%   34C    P8             29W /  300W |      18MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000               Off |   00000000:24:00.0 Off |                  Off |\n",
      "| 44%   75C    P0            295W /  300W |   20024MiB /  49140MiB |     98%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA RTX 6000 Ada Gene...    Off |   00000000:E1:00.0 Off |                  Off |\n",
      "| 34%   60C    P0            131W /  300W |   47574MiB /  49140MiB |     29%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      5747      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "|    1   N/A  N/A      5747      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "|    1   N/A  N/A   1603377      C   ...ngli/miniconda3/envs/pyg/bin/python      19998MiB |\n",
      "|    2   N/A  N/A      5747      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "|    2   N/A  N/A    884984      C   ...ngli/miniconda3/envs/pyg/bin/python       2300MiB |\n",
      "|    2   N/A  N/A   1603377      C   ...ngli/miniconda3/envs/pyg/bin/python       1454MiB |\n",
      "|    2   N/A  N/A   1603401      C   ...ngli/miniconda3/envs/pyg/bin/python      43782MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "703f5af4-0ab4-4368-bdbd-d348784b1a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up device\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "gpu_id = 0\n",
    "torch.cuda.set_device(gpu_id)\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789cf3af-a8ad-4d4d-965c-f19f97060d60",
   "metadata": {},
   "source": [
    "## submodule/module configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "027ecaa1-799d-4ea9-971a-92a606013e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = Path('checkpoints/')\n",
    "with open(checkpoint_path/'config.yaml', 'r', encoding='UTF-8') as handle:\n",
    "    config = yaml.safe_load(handle)\n",
    "\n",
    "gnn = assemble_gnn(config['gnn_model'])\n",
    "checkpoint = torch.load(checkpoint_path/'ckpt_last.pth', weights_only=True)\n",
    "gnn.load_state_dict(checkpoint['model'])\n",
    "_ = gnn.eval()\n",
    "gnn = gnn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909abd3-b7fe-484f-848b-2f5e39d73900",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e4ea06b-e9a2-46cb-b7e0-89c49f8602d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Processor(**config['data_processor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4c7b8a1-d107-4fc0-aa2f-bb22d0b965a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 13106 events from /home/sphenix_fm/data/pp_100k_mmap-with_charge!\n",
      "\n",
      "775 24023\n",
      "ARI: 0.8421893254497874\n",
      "efficiency: 0.9333333333333333\n",
      "purity: 0.7368421052631579\n"
     ]
    }
   ],
   "source": [
    "config['data']['target'] = ['reg', 'seg']\n",
    "valid_ds  = TPCDataset(split='test', **config['data'])\n",
    "valid_ldr = DataLoader(valid_ds, batch_size=1, shuffle=True)\n",
    "\n",
    "data = next(iter(valid_ldr))\n",
    "\n",
    "points    = data['features'].x.to(device)\n",
    "track_ids = data['seg_target'].x.to(device)\n",
    "batch     = data['features'].batch.to(device)\n",
    "\n",
    "edge_index = data['edge_index'].x.to(device)\n",
    "edge_batch = data['edge_index'].batch.to(device)\n",
    "\n",
    "\n",
    "# processing filter_input\n",
    "inputs, head_indices, tail_indices, labels, truncated = processor(\n",
    "    points     = points,\n",
    "    track_ids  = track_ids,\n",
    "    batch      = batch,\n",
    "    edge_index = edge_index,\n",
    "    edge_batch = edge_batch\n",
    ")\n",
    "\n",
    "# run gnn model\n",
    "with torch.no_grad():\n",
    "    logits = gnn(inputs, head_indices, tail_indices)\n",
    "\n",
    "probs = torch.sigmoid(logits)\n",
    "#     _, _, auc = compute_roc(probs, labels, vmin=0, vmax=1, reverse=False)\n",
    "#     _, _, avg_precision = compute_pr(probs, labels, vmin=0, vmax=1, reverse=False)\n",
    "\n",
    "# # Calculate and evaluate performance \n",
    "# plot_distribution(probs, labels, data_type='probability', log_y=False)\n",
    "# plot_distribution(probs, labels, data_type='probability', log_y=True)\n",
    "# # ROC curve\n",
    "# fpr, tpr, auc = compute_roc(probs, labels, num_thresholds=100)\n",
    "# plot_roc_curve(fpr, tpr, auc)\n",
    "# # PR curve\n",
    "# recall, precision, average_precision = compute_pr(probs, labels, num_thresholds=100)\n",
    "# plot_pr_curve(recall, precision, average_precision)\n",
    "\n",
    "\n",
    "# connected component\n",
    "threshold = .9\n",
    "mask = probs > threshold\n",
    "edges = torch.stack([head_indices[mask], tail_indices[mask]]).detach().cpu().numpy()\n",
    "num_edges = edges.shape[1]\n",
    "num_vertices = len(inputs)\n",
    "print(num_vertices, num_edges)\n",
    "\n",
    "# get connected components\n",
    "sparse_edges = sp.coo_matrix((np.ones(num_edges), edges),\n",
    "                             shape=(num_vertices, num_vertices))\n",
    "\n",
    "connected_components = scigraph.connected_components(sparse_edges)[1]\n",
    "# print(connected_components)\n",
    "ari = adjusted_rand_score(connected_components, track_ids.cpu().numpy())\n",
    "print(f'ARI: {ari}')\n",
    "\n",
    "efficiency, purity, cell = calc_efficiency_purity(connected_components, \n",
    "                                                  track_ids.cpu().numpy(), \n",
    "                                                  return_df=True)\n",
    "print(f'efficiency: {efficiency}')\n",
    "print(f'purity: {purity}')\n",
    "# # attach labels to data\n",
    "# graph.labels = connected_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52e15bab-2a39-4b33-8f30-7382f25e43e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 13106 events from /home/sphenix_fm/data/pp_100k_mmap-with_charge!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea06b28c805483091b6974d8b5e8c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "evaluation:   0%|          | 0/13106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ari</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>purity</th>\n",
       "      <th>event_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13106.000000</td>\n",
       "      <td>13106.000000</td>\n",
       "      <td>13106.000000</td>\n",
       "      <td>13106.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.859604</td>\n",
       "      <td>0.900199</td>\n",
       "      <td>0.767196</td>\n",
       "      <td>6553.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.174839</td>\n",
       "      <td>0.122639</td>\n",
       "      <td>0.232422</td>\n",
       "      <td>3783.520649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.100212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.779448</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>3277.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.930678</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>6553.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.994689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9829.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13106.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ari    efficiency        purity     event_idx\n",
       "count  13106.000000  13106.000000  13106.000000  13106.000000\n",
       "mean       0.859604      0.900199      0.767196   6553.500000\n",
       "std        0.174839      0.122639      0.232422   3783.520649\n",
       "min       -0.100212      0.000000      0.000000      1.000000\n",
       "25%        0.779448      0.846154      0.636364   3277.250000\n",
       "50%        0.930678      0.931034      0.823529   6553.500000\n",
       "75%        0.994689      1.000000      1.000000   9829.750000\n",
       "max        1.000000      1.000000      1.000000  13106.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['data']['target'] = ['reg', 'seg']\n",
    "valid_ds  = TPCDataset(split='test', **config['data'])\n",
    "valid_ldr = DataLoader(valid_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "columns = ['true_label', 'px', 'py', 'pz', 'vtx_x', 'vtx_y', 'vtx_z', 'q', 'e']\n",
    "cumulator = Cumulator()\n",
    "\n",
    "pbar = tqdm(enumerate(valid_ldr, start=1), total=len(valid_ldr), desc='evaluation')\n",
    "\n",
    "threshold = .8\n",
    "folder = Path(f'results/events_gnn-{int(threshold * 100)}')\n",
    "if not folder.exists():\n",
    "    folder.mkdir(parents=True)\n",
    "\n",
    "stat = defaultdict(list)\n",
    "for event_idx, data in pbar:\n",
    "\n",
    "    points    = data['features'].x.to(device)\n",
    "    track_ids = data['seg_target'].x.to(device)\n",
    "    batch     = data['features'].batch.to(device)\n",
    "    particles = data['reg_target'].x # we don't need it to be on gpu\n",
    "    \n",
    "    edge_index = data['edge_index'].x.to(device)\n",
    "    edge_batch = data['edge_index'].batch.to(device)\n",
    "    \n",
    "    \n",
    "    # processing filter_input\n",
    "    inputs, head_indices, tail_indices, labels, truncated = processor(\n",
    "        points     = points,\n",
    "        track_ids  = track_ids,\n",
    "        batch      = batch,\n",
    "        edge_index = edge_index,\n",
    "        edge_batch = edge_batch\n",
    "    )\n",
    "    \n",
    "    # run gnn model\n",
    "    with torch.no_grad():\n",
    "        logits = gnn(inputs, head_indices, tail_indices)\n",
    "    \n",
    "    probs = torch.sigmoid(logits)\n",
    "\n",
    "    # connected component    \n",
    "    mask = probs > threshold\n",
    "    edges = torch.stack([head_indices[mask], tail_indices[mask]]).detach().cpu().numpy()\n",
    "    num_edges = edges.shape[1]\n",
    "    num_vertices = len(inputs)\n",
    "    \n",
    "    # get connected components\n",
    "    sparse_edges = sp.coo_matrix((np.ones(num_edges), edges),\n",
    "                                 shape=(num_vertices, num_vertices))\n",
    "    \n",
    "    connected_components = scigraph.connected_components(sparse_edges)[1]\n",
    "    ari = adjusted_rand_score(connected_components, track_ids.cpu().numpy())\n",
    "    \n",
    "    efficiency, purity, cell = calc_efficiency_purity(connected_components, \n",
    "                                                      track_ids.cpu().numpy(), \n",
    "                                                      return_df=True)\n",
    "    metrics = {'ari': ari, \n",
    "               'efficiency': efficiency, \n",
    "               'purity': purity}\n",
    "    \n",
    "    # save metrics\n",
    "    for key, val in metrics.items():\n",
    "        stat[key].append(val)\n",
    "    stat['event_idx'].append(event_idx)\n",
    "    \n",
    "    cumulator.update(metrics)\n",
    "    metrics = cumulator.get_average()\n",
    "    pbar.set_postfix(metrics)\n",
    "\n",
    "    # per-event track hit metric\n",
    "    record = torch.hstack([track_ids.unsqueeze(-1).cpu(), particles])\n",
    "    df = pd.DataFrame(data=record, columns=columns)\n",
    "    df['true_label'] = df['true_label'].astype(int)\n",
    "    cell = cell.merge(df.drop_duplicates(subset='true_label', keep='first'), on='true_label')\n",
    "    cell.to_csv(f'results/events_gnn-{int(threshold * 100)}/test_event-{event_idx}.csv', index=False)\n",
    "\n",
    "metrics = pd.DataFrame(data=stat)\n",
    "metrics.to_csv(f'results/test_gnn-{int(threshold * 100)}_metrics.csv', index=False)\n",
    "metrics.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a39e896-9085-48b7-b501-a6a8e12008eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d38ae9c9d942309962638eae582130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_fnames = sorted(list(Path(f'results/events_gnn-{int(threshold * 100)}/').glob('*csv')), key=lambda fname: int(fname.stem.split('-')[-1]))\n",
    "\n",
    "combined_dfs = []\n",
    "for event_idx, csv_fname in tqdm(enumerate(csv_fnames, start=1), total=len(csv_fnames)):\n",
    "    df = pd.read_csv(csv_fname)\n",
    "    df['pT'] = np.sqrt(df['px']**2 + df['py']**2)\n",
    "    temp = pd.concat([df.groupby('true_label')['matched'].any(), \n",
    "                      df.groupby('true_label')['pT'].mean()], axis=1).reset_index()\n",
    "    temp['event_idx'] = event_idx\n",
    "    combined_dfs.append(temp)\n",
    "\n",
    "combined_df = pd.concat(combined_dfs, axis=0)\n",
    "combined_df.to_csv(f'results/test_gnn-{int(threshold * 100)}_tracking_efficiency.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d034657-5bf7-4c8f-889a-2d901e98b5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9259878419452887"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pt = combined_df[combined_df.pT > 1]\n",
    "df_pt.matched.sum() / len(df_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86d128f9-bcbd-49af-8db9-73ba4175c239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b179c1edc974265b34a1cbc1f98006a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall hit efficiency = 0.9639638341489517\n"
     ]
    }
   ],
   "source": [
    "csv_fnames = sorted(list(Path(f'results/events_gnn-{int(threshold * 100)}/').glob('*csv')), key=lambda fname: int(fname.stem.split('-')[-1]))\n",
    "\n",
    "combined_dfs = []\n",
    "for event_idx, csv_fname in tqdm(enumerate(csv_fnames, start=1), total=len(csv_fnames)):\n",
    "    \n",
    "    df = pd.read_csv(csv_fname)\n",
    "    df['pT'] = np.sqrt(df['px']**2 + df['py']**2)\n",
    "    temp = df.groupby('true_label')[['true_ratio', 'pT']].max().reset_index()\n",
    "\n",
    "    temp['event_idx'] = event_idx\n",
    "    combined_dfs.append(temp)\n",
    "\n",
    "combined_df = pd.concat(combined_dfs, axis=0)\n",
    "combined_df.to_csv(f'results/test_gnn-{int(threshold * 100)}_hit_efficiency.csv', index=False)\n",
    "hit_efficiency = combined_df['true_ratio'].mean()\n",
    "print(f'overall hit efficiency = {hit_efficiency}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74ebfa78-28a6-4dcb-a6b9-cbfd634aaaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22252a821f7f4e3f8cf9156089a2de90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall hit purity = 0.9774567254274198\n"
     ]
    }
   ],
   "source": [
    "csv_fnames = sorted(list(Path(f'results/events_gnn-{int(threshold * 100)}/').glob('*csv')), key=lambda fname: int(fname.stem.split('-')[-1]))\n",
    "\n",
    "combined_dfs = []\n",
    "for event_idx, csv_fname in tqdm(enumerate(csv_fnames, start=1), total=len(csv_fnames)):\n",
    "    \n",
    "    df = pd.read_csv(csv_fname)\n",
    "    temp = df.groupby('pred_label')[['pred_ratio']].max().reset_index()\n",
    "    temp['event_idx'] = event_idx\n",
    "    combined_dfs.append(temp)\n",
    "\n",
    "combined_df = pd.concat(combined_dfs, axis=0)\n",
    "combined_df.to_csv(f'results/test_gnn-{int(threshold * 100)}_hit_purity.csv', index=False)\n",
    "hit_purity = combined_df['pred_ratio'].mean()\n",
    "print(f'overall hit purity = {hit_purity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8187ffc-6433-4116-ba0e-980c995c4cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "pyg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
